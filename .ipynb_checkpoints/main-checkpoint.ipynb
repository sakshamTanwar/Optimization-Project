{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \n",
    "    A = 1/(1 + np.exp(-Z))\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "def relu(Z):\n",
    "    \n",
    "    A = np.maximum(0, Z)\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "def softmax(Z):\n",
    "    \n",
    "    A = np.exp(Z)\n",
    "    A = A / np.sum(A, axis = 0)\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    \n",
    "    Z = cache\n",
    "    s = 1/(1 + np.exp(-Z))\n",
    "    dZ = dA * s * (1 - s)\n",
    "    \n",
    "    assert(dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert(dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def softmax_backward(dA, cache):\n",
    "    \n",
    "    Z = cache\n",
    "    \n",
    "    dZ = Z\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.rand(layer_dims[l], layer_dims[l-1])*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    Z = np.dot(W, A) + b\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the post-activation value \n",
    "    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";\n",
    "             stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        \n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        \n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    elif activation == \"softmax\":\n",
    "        \n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = softmax(Z)\n",
    "    \n",
    "    assert(A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], \"relu\")\n",
    "        caches.append(cache)\n",
    "    \n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], \"softmax\")\n",
    "    caches.append(cache)\n",
    "    \n",
    "    #assert(AL.shape == ())\n",
    "    \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "        \n",
    "    cost = (-1/m)*np.sum(np.multiply(Y, np.log(AL)))\n",
    "    \n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Propagation Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    \n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    dW = (1/m) * np.dot(dZ, A_prev.T)\n",
    "    db = (1/m) * np.sum(dZ, axis = 1, keepdims = True)\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation, data):\n",
    "    linear_cache, activation_cache = cache\n",
    "    Y = data\n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    elif activation == \"softmax\":\n",
    "        dZ = dA - Y\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    return dA_prev, dW, db\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    m = AL.shape[1]\n",
    "    dAL = 0\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(AL, current_cache, \"softmax\", Y)\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l+1)], current_cache, \"relu\", Y)\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters)//2\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate*grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate*grads[\"db\" + str(l+1)]\n",
    "    \n",
    "    return parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_csv(csv_file):\n",
    "    all_data = pd.read_csv(csv_file)\n",
    "    all_data_np = all_data.values\n",
    "    X = all_data_np[:, 1:]\n",
    "    X = X.T\n",
    "    X = X / 255\n",
    "    Y = all_data_np[:, 0]\n",
    "    Y = Y.reshape((Y.shape[0], 1))\n",
    "    Y = Y.T\n",
    "    digits = 10\n",
    "    Y_new = np.eye(digits)[Y.astype('int32')]\n",
    "    Y_new = Y_new.T.reshape(digits, Y.shape[1])\n",
    "    \n",
    "    return X, Y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = get_data_from_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dims = [784, 64, 32, 16, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layer_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost = False):\n",
    "    costs = []\n",
    "    \n",
    "    parameters = initialize_parameters(layer_dims)\n",
    "    for i in range(num_iterations):\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        \n",
    "        cost = compute_cost(AL, Y)\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        \n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration %i: %f\" %(i, cost))\n",
    "            costs.append(cost)\n",
    "    \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 2.302592\n",
      "Cost after iteration 100: 2.301142\n",
      "Cost after iteration 200: 2.300113\n",
      "Cost after iteration 300: 2.296851\n",
      "Cost after iteration 400: 2.270066\n",
      "Cost after iteration 500: 2.094925\n",
      "Cost after iteration 600: 1.908829\n",
      "Cost after iteration 700: 1.827708\n",
      "Cost after iteration 800: 1.777873\n",
      "Cost after iteration 900: 1.735818\n",
      "Cost after iteration 1000: 1.699770\n",
      "Cost after iteration 1100: 1.667101\n",
      "Cost after iteration 1200: 1.638565\n",
      "Cost after iteration 1300: 1.613323\n",
      "Cost after iteration 1400: 1.590532\n",
      "Cost after iteration 1500: 1.569131\n",
      "Cost after iteration 1600: 1.547241\n",
      "Cost after iteration 1700: 1.524682\n",
      "Cost after iteration 1800: 1.502037\n",
      "Cost after iteration 1900: 1.479778\n",
      "Cost after iteration 2000: 1.461174\n",
      "Cost after iteration 2100: 1.440666\n",
      "Cost after iteration 2200: 1.422404\n",
      "Cost after iteration 2300: 1.405219\n",
      "Cost after iteration 2400: 1.388080\n",
      "Cost after iteration 2500: 1.374575\n",
      "Cost after iteration 2600: 1.363732\n",
      "Cost after iteration 2700: 1.351272\n",
      "Cost after iteration 2800: 1.340307\n",
      "Cost after iteration 2900: 1.331239\n",
      "Cost after iteration 3000: 1.322830\n",
      "Cost after iteration 3100: 1.315295\n",
      "Cost after iteration 3200: 1.303889\n",
      "Cost after iteration 3300: 1.289158\n",
      "Cost after iteration 3400: 1.275329\n",
      "Cost after iteration 3500: 1.269282\n",
      "Cost after iteration 3600: 1.262991\n",
      "Cost after iteration 3700: 1.254498\n",
      "Cost after iteration 3800: 1.241876\n",
      "Cost after iteration 3900: 1.219691\n",
      "Cost after iteration 4000: 1.199636\n",
      "Cost after iteration 4100: 1.180421\n",
      "Cost after iteration 4200: 1.149128\n",
      "Cost after iteration 4300: 1.085154\n",
      "Cost after iteration 4400: 1.013526\n",
      "Cost after iteration 4500: 0.966434\n",
      "Cost after iteration 4600: 0.928820\n",
      "Cost after iteration 4700: 0.895272\n",
      "Cost after iteration 4800: 0.865776\n",
      "Cost after iteration 4900: 0.843238\n",
      "Cost after iteration 5000: 0.825680\n",
      "Cost after iteration 5100: 0.803660\n",
      "Cost after iteration 5200: 0.789634\n",
      "Cost after iteration 5300: 0.776965\n",
      "Cost after iteration 5400: 0.760695\n",
      "Cost after iteration 5500: 0.750427\n",
      "Cost after iteration 5600: 0.738835\n",
      "Cost after iteration 5700: 0.728458\n",
      "Cost after iteration 5800: 0.715977\n",
      "Cost after iteration 5900: 0.707955\n",
      "Cost after iteration 6000: 0.704026\n",
      "Cost after iteration 6100: 0.691310\n",
      "Cost after iteration 6200: 0.683383\n",
      "Cost after iteration 6300: 0.672640\n",
      "Cost after iteration 6400: 0.646835\n",
      "Cost after iteration 6500: 0.603590\n",
      "Cost after iteration 6600: 0.552841\n",
      "Cost after iteration 6700: 0.510881\n",
      "Cost after iteration 6800: 0.484207\n",
      "Cost after iteration 6900: 0.462852\n",
      "Cost after iteration 7000: 0.447347\n",
      "Cost after iteration 7100: 0.432862\n",
      "Cost after iteration 7200: 0.417943\n",
      "Cost after iteration 7300: 0.378490\n",
      "Cost after iteration 7400: 0.340162\n",
      "Cost after iteration 7500: 0.303215\n",
      "Cost after iteration 7600: 0.280883\n",
      "Cost after iteration 7700: 0.264585\n",
      "Cost after iteration 7800: 0.251591\n",
      "Cost after iteration 7900: 0.241783\n",
      "Cost after iteration 8000: 0.234198\n",
      "Cost after iteration 8100: 0.225081\n",
      "Cost after iteration 8200: 0.215669\n",
      "Cost after iteration 8300: 0.581645\n",
      "Cost after iteration 8400: 0.193411\n",
      "Cost after iteration 8500: 0.168030\n",
      "Cost after iteration 8600: 0.150231\n",
      "Cost after iteration 8700: 0.136482\n",
      "Cost after iteration 8800: 0.125145\n",
      "Cost after iteration 8900: 0.113498\n",
      "Cost after iteration 9000: 0.175464\n",
      "Cost after iteration 9100: 0.135335\n",
      "Cost after iteration 9200: 0.122100\n",
      "Cost after iteration 9300: 0.111118\n",
      "Cost after iteration 9400: 0.102502\n",
      "Cost after iteration 9500: 0.095377\n",
      "Cost after iteration 9600: 0.089498\n",
      "Cost after iteration 9700: 0.084237\n",
      "Cost after iteration 9800: 0.087958\n",
      "Cost after iteration 9900: 0.074818\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = L_layer_model(X_train, Y_train, layer_dims, 0.075, 10000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(parameters, open(\"model1.sav\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_arr = pd.read_csv(\"test.csv\").values\n",
    "X_test = np_arr.T\n",
    "X_test = X_test/255\n",
    "\n",
    "AL, _ = L_model_forward(X_test, parameters)\n",
    "predictions = np.argmax(AL, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.reshape(predictions.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions, columns = ['Label'])\n",
    "predictions.index += 1\n",
    "predictions.to_csv(\"predic2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
